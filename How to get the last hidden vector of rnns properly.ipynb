{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if the last hidden state is correct when there're paddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(x, seqlens=None, reuse=False):\n",
    "    with tf.variable_scope(\"rnn\", reuse=reuse):\n",
    "        cell = tf.contrib.rnn.GRUCell(2)\n",
    "        outputs, last_hidden = tf.nn.dynamic_rnn(cell, x, sequence_length=seqlens, dtype=tf.float32)\n",
    "    return outputs, last_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no padding\n",
    "x1 = tf.constant([1, 2, 3])\n",
    "x1 = tf.one_hot(tf.expand_dims(x1, 0), 4)\n",
    "outputs1, last_hidden1 = rnn(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero padding, no seqlens\n",
    "x2 = tf.constant([1, 2, 3, 0])\n",
    "x2 = tf.one_hot(tf.expand_dims(x2, 0), 4)\n",
    "outputs2, last_hidden2 = rnn(x2, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero padding with explicit seqlens\n",
    "outputs3, last_hidden3 = rnn(x2, seqlens=[3,], reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.11338668,  0.02229878],\n",
       "        [-0.16635834, -0.19894187],\n",
       "        [ 0.00041986, -0.24142244]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.11338668,  0.02229878],\n",
       "        [-0.16635834, -0.19894187],\n",
       "        [ 0.00041986, -0.24142244],\n",
       "        [-0.00597491, -0.20334211]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.11338668,  0.02229878],\n",
       "        [-0.16635834, -0.19894187],\n",
       "        [ 0.00041986, -0.24142244],\n",
       "        [ 0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00041986, -0.24142244]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00597491, -0.20334211]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00041986, -0.24142244]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden3.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion: when you add paddings, you should add seqlens in order to get correct results. Paddings are masked to zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def birnn(x, seqlens=None, reuse=False):\n",
    "    with tf.variable_scope(\"birnn\", reuse=reuse):\n",
    "        cell = tf.contrib.rnn.GRUCell(1)\n",
    "        cell_bw = tf.contrib.rnn.GRUCell(1)\n",
    "        outputs, last_hidden = tf.nn.bidirectional_dynamic_rnn(cell, cell_bw, x, sequence_length=seqlens, dtype=tf.float32)\n",
    "    return tf.concat(outputs,-1), tf.concat(last_hidden, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = tf.constant([1, 2, 3])\n",
    "x1 = tf.one_hot(tf.expand_dims(x1, 0), 4)\n",
    "outputs1, last_hidden1 = birnn(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = tf.constant([1, 2, 3, 0])\n",
    "x2 = tf.one_hot(tf.expand_dims(x2, 0), 4)\n",
    "outputs2, last_hidden2 = birnn(x2, seqlens=[3,], reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.24943233, -0.08515487],\n",
       "        [ 0.05219585, -0.21929769],\n",
       "        [-0.21960783,  0.08647518]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.24943233, -0.08515487],\n",
       "        [ 0.05219585, -0.21929769],\n",
       "        [-0.21960783,  0.08647518],\n",
       "        [ 0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21960783, -0.08515487]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21960783, -0.08515487]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in bidirectional rnns, last_hidden of forward rnn (=-0.21960783), which is the rightmost one in the sequence is concatenated with the last hidden state of backward rnn (=-0.08515487), which is the leftmost one!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(arry, size):\n",
    "    '''\n",
    "    arry: 2-d array of n, t\n",
    "    size: output dimensions\n",
    "    \n",
    "    returns\n",
    "    3-d array of (n, t, size)\n",
    "    '''\n",
    "    labels_one_hot = (arry.ravel()[np.newaxis] == np.arange(size)[:, np.newaxis]).T\n",
    "    labels_one_hot.shape = arry.shape + (size,)\n",
    "    return labels_one_hot.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(4, 2, batch_first=True)\n",
    "        \n",
    "    def forward(self, x, seqlens=None):\n",
    "        if seqlens is None:\n",
    "            outputs, last_hidden = self.rnn(x)\n",
    "            last_hidden = last_hidden.permute(1,2, 0)\n",
    "            last_hidden = last_hidden.view(last_hidden.size()[0], -1)\n",
    "        else:\n",
    "            # sorting by seqlens\n",
    "            seqlens = torch.IntTensor(seqlens)\n",
    "            seqlens_sorted, perm_idx = seqlens.sort(0, descending=True)\n",
    "            _, unperm_idx = perm_idx.sort(0) # for recovery\n",
    "            x = x[perm_idx]\n",
    "            \n",
    "            # packing -> rnn -> unpacking -> position recovery\n",
    "            packed_input = pack_padded_sequence(x, seqlens_sorted, batch_first=True)   \n",
    "            outputs, last_hidden = self.rnn(packed_input)\n",
    "            outputs, _ = pad_packed_sequence(outputs, batch_first=True, total_length=x.size()[1])\n",
    "            outputs = outputs[unperm_idx]\n",
    "\n",
    "            # last hidden\n",
    "            last_hidden = last_hidden.permute(1,2, 0)\n",
    "            last_hidden = last_hidden.view(last_hidden.size()[0], -1)\n",
    "            last_hidden = last_hidden[unperm_idx]\n",
    "        \n",
    "        return outputs, last_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array([1, 2, 3])\n",
    "x1 = onehot(np.expand_dims(x1, 0), 4)\n",
    "x1 = torch.from_numpy(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.array([1, 2, 3, 0])\n",
    "x2 = onehot(np.expand_dims(x2, 0), 4)\n",
    "x2 = torch.from_numpy(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no padding\n",
    "model1 = Rnn()\n",
    "outputs1, last_hidden1 = model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero padding, no seqlens\n",
    "model2 = Rnn()\n",
    "for p1, p2 in zip(model1.parameters(), model2.parameters()):\n",
    "    p2.data = p1.data\n",
    "outputs2, last_hidden2 = model2(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero padding with explicit seqlens\n",
    "model3 = Rnn()\n",
    "for p1, p3 in zip(model1.parameters(), model3.parameters()):\n",
    "    p3.data = p1.data\n",
    "outputs3, last_hidden3 = model3(x2, seqlens=[3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1044,  0.3741],\n",
       "         [-0.3837,  0.3580],\n",
       "         [-0.3023,  0.4439]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1044,  0.3741],\n",
       "         [-0.3837,  0.3580],\n",
       "         [-0.3023,  0.4439],\n",
       "         [-0.1070,  0.2071]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1044,  0.3741],\n",
       "         [-0.3837,  0.3580],\n",
       "         [-0.3023,  0.4439],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3023,  0.4439]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1070,  0.2071]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3023,  0.4439]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same here. Because there's no such argument as seqlens in pytorch, a trick was used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRnn(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(4, 1, batch_first=True, bidirectional=True)\n",
    "        \n",
    "    def forward(self, x, seqlens=None):\n",
    "        if seqlens is None:\n",
    "            outputs, last_hidden = self.rnn(x)\n",
    "            last_hidden = last_hidden.permute(1,2, 0)\n",
    "            last_hidden = last_hidden.view(last_hidden.size()[0], -1)\n",
    "        else:\n",
    "            # sorting by seqlens\n",
    "            seqlens = torch.IntTensor(seqlens)\n",
    "            seqlens_sorted, perm_idx = seqlens.sort(0, descending=True)\n",
    "            _, unperm_idx = perm_idx.sort(0) # for recovery\n",
    "            x = x[perm_idx]\n",
    "            \n",
    "            # packing -> rnn -> unpacking -> position recovery\n",
    "            packed_input = pack_padded_sequence(x, seqlens_sorted, batch_first=True)   \n",
    "            outputs, last_hidden = self.rnn(packed_input)\n",
    "            outputs, _ = pad_packed_sequence(outputs, batch_first=True, total_length=x.size()[1])\n",
    "            outputs = outputs[unperm_idx]\n",
    "\n",
    "            # last hidden\n",
    "            last_hidden = last_hidden.permute(1,2, 0)\n",
    "            last_hidden = last_hidden.view(last_hidden.size()[0], -1)\n",
    "            last_hidden = last_hidden[unperm_idx]\n",
    "        \n",
    "        return outputs, last_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no padding\n",
    "model1 = BiRnn()\n",
    "outputs1, last_hidden1 = model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero padding with explicit seqlens\n",
    "model2 = BiRnn()\n",
    "for p1, p2 in zip(model1.parameters(), model2.parameters()):\n",
    "    p2.data = p1.data\n",
    "outputs2, last_hidden2 = model2(x2, seqlens=[3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2045,  0.9008],\n",
       "         [-0.5576,  0.8139],\n",
       "         [-0.5149,  0.4902]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2045,  0.9008],\n",
       "         [-0.5576,  0.8139],\n",
       "         [-0.5149,  0.4902],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5149,  0.9008]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5149,  0.9008]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = np.array([[1, 2, 0, 0], [3, 2, 1, 0]])\n",
    "x2 = onehot(x2, 4)\n",
    "x2 = torch.from_numpy(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero padding with explicit seqlens\n",
    "model3 = BiRnn()\n",
    "for p1, p2 in zip(model1.parameters(), model3.parameters()):\n",
    "    p2.data = p1.data\n",
    "outputs2, last_hidden2 = model3(x2, seqlens=[2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2045,  0.8737],\n",
       "         [-0.5576,  0.7316],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.0955,  0.7689],\n",
       "         [-0.4913,  0.8491],\n",
       "         [-0.5968,  0.6703],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5576,  0.8737],\n",
       "        [-0.5968,  0.7689]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
