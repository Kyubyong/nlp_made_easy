{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see how to get the last hidden states of Rnns in Tensorflow and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"kyubyong\"\n",
    "__address__ = \"https://github.com/kyubyong/nlp_made_easy\"\n",
    "__email__ = \"kbpark.linguist@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn(x, bidirectional=False, seqlens=None, reuse=False):\n",
    "    if not bidirectional:\n",
    "        with tf.variable_scope(\"rnn\", reuse=reuse):\n",
    "            cell = tf.contrib.rnn.GRUCell(1)\n",
    "            outputs, last_hidden = tf.nn.dynamic_rnn(cell, x, sequence_length=seqlens, dtype=tf.float32)\n",
    "    else: \n",
    "        with tf.variable_scope(\"birnn\", reuse=reuse):\n",
    "            cell = tf.contrib.rnn.GRUCell(1)\n",
    "            cell_bw = tf.contrib.rnn.GRUCell(1)\n",
    "            outputs, last_hidden = tf.nn.bidirectional_dynamic_rnn(cell, cell_bw, x, sequence_length=seqlens, dtype=tf.float32)\n",
    "            outputs, last_hidden = tf.concat(outputs,-1), tf.concat(last_hidden, -1)\n",
    "\n",
    "    return outputs, last_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(arry, size):\n",
    "    '''\n",
    "    arry: 2-d array of n, t\n",
    "    size: output dimensions\n",
    "    \n",
    "    returns\n",
    "    3-d array of (n, t, size)\n",
    "    '''\n",
    "    labels_one_hot = (arry.ravel()[np.newaxis] == np.arange(size)[:, np.newaxis]).T\n",
    "    labels_one_hot.shape = arry.shape + (size,)\n",
    "    return labels_one_hot.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_x1 = np.array([1, 2, 3], np.int32)\n",
    "_x1 = onehot(np.expand_dims(_x1, 0), 4)\n",
    "\n",
    "_x2 = np.array([1, 2, 3, 0], np.int32) # 0 means padding\n",
    "_x2 = onehot(np.expand_dims(_x2, 0), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. no padding\n",
    "x1 = tf.convert_to_tensor(_x1)\n",
    "outputs1, last_hidden1 = rnn(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. zero padding, no seqlens\n",
    "x2 = tf.convert_to_tensor(_x2)\n",
    "outputs2, last_hidden2 = rnn(x2, reuse=True) # We want to sync the variables up to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. zero padding with explicit seqlens\n",
    "outputs3, last_hidden3 = rnn(x2, seqlens=[3,], reuse=True) # Real sequence length is 3 as the last 0 is a padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01561858],\n",
       "        [ 0.19808015],\n",
       "        [-0.00724778]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01561858],\n",
       "        [ 0.19808015],\n",
       "        [-0.00724778],\n",
       "        [-0.2128418 ]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2.eval() # the last step has non-zero outputs. This is not we usually want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01561858],\n",
       "        [ 0.19808015],\n",
       "        [-0.00724778],\n",
       "        [ 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs3.eval() # the last step is masked to zeros. This is usually correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00724778]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2128418]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00724778]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden3.eval() # Now we have the same results as # 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â–³ Comment: Paddings are mostly added to construct mini-batches from multiples samples of variable lengths. Therefore typically we want to get the same results as the case we treat them individually and do not pad. To that end, when you add paddings, you should add `seqlens`. Paddings are masked to zeros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. no padding\n",
    "x1 = tf.convert_to_tensor(_x1)\n",
    "outputs1, last_hidden1 = rnn(x1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. zero padding, no seqlens\n",
    "x2 = tf.convert_to_tensor(_x2)\n",
    "outputs2, last_hidden2 = rnn(x2, bidirectional=True, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. zero padding with explicit seqlens\n",
    "outputs3, last_hidden3 = rnn(x2, bidirectional=True, seqlens=[3,], reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.01149251,  0.16380599],\n",
       "        [ 0.09828447,  0.043238  ],\n",
       "        [-0.03214497,  0.04969781]]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.01149251,  0.15307006],\n",
       "        [ 0.09828447,  0.02596181],\n",
       "        [-0.03214497,  0.02305467],\n",
       "        [-0.10564233, -0.03366997]]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2.eval() # Again, this is not we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.01149251,  0.16380599],\n",
       "        [ 0.09828447,  0.043238  ],\n",
       "        [-0.03214497,  0.04969781],\n",
       "        [ 0.        ,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs3.eval() # Again, note that the last step is masked to zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03214497,  0.16380599]], dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.10564233,  0.15307006]], dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03214497,  0.16380599]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden3.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â–³ Note that in bidirectional rnns, the last_hidden state of the forward rnn (=-0.03214497) is from the rightmost step in the sequence, while the last hidden state of the backward rnn (=0.16380599) is from the leftmost step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uni-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rnn(torch.nn.Module):\n",
    "    def __init__(self, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(4, 1, batch_first=True, bidirectional=bidirectional)\n",
    "        \n",
    "    def forward(self, x, seqlens=None):\n",
    "        if seqlens is None:\n",
    "            outputs, last_hidden = self.rnn(x)\n",
    "            last_hidden = last_hidden.permute(1, 2, 0) # to (batch, hidden, num_directions)\n",
    "            last_hidden = last_hidden.view(last_hidden.size()[0], -1) # to (batch, hidden*num_directions)\n",
    "        else:\n",
    "            # This may look complicated ... but it corresponds to the `seqlens` argument in TF. We'll see..\n",
    "            # sorting by seqlens\n",
    "            seqlens = torch.IntTensor(seqlens)\n",
    "            seqlens_sorted, perm_idx = seqlens.sort(0, descending=True)\n",
    "            _, unperm_idx = perm_idx.sort(0) # for recovery\n",
    "            x = x[perm_idx]\n",
    "            \n",
    "            # packing -> rnn -> unpacking -> position recovery\n",
    "            packed_input = pack_padded_sequence(x, seqlens_sorted, batch_first=True)   \n",
    "            outputs, last_hidden = self.rnn(packed_input)\n",
    "            outputs, _ = pad_packed_sequence(outputs, batch_first=True, total_length=x.size()[1])\n",
    "            outputs = outputs[unperm_idx]\n",
    "\n",
    "            # last hidden\n",
    "            last_hidden = last_hidden.permute(1, 2, 0)\n",
    "            last_hidden = last_hidden.view(last_hidden.size()[0], -1)\n",
    "            last_hidden = last_hidden[unperm_idx]\n",
    "        \n",
    "        return outputs, last_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. no padding\n",
    "x1 = torch.from_numpy(_x1)\n",
    "model1 = Rnn()\n",
    "outputs1, last_hidden1 = model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. zero padding, no seqlens\n",
    "x2 = torch.from_numpy(_x2)\n",
    "model2 = Rnn()\n",
    "for p1, p2 in zip(model1.parameters(), model2.parameters()): # sync up the variables\n",
    "    p2.data = p1.data\n",
    "outputs2, last_hidden2 = model2(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. zero padding with explicit seqlens\n",
    "model3 = Rnn()\n",
    "for p1, p3 in zip(model1.parameters(), model3.parameters()):\n",
    "    p3.data = p1.data\n",
    "outputs3, last_hidden3 = model3(x2, seqlens=[3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4626],\n",
       "         [0.6538],\n",
       "         [0.7014]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4626],\n",
       "         [0.6538],\n",
       "         [0.7014],\n",
       "         [0.7997]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4626],\n",
       "         [0.6538],\n",
       "         [0.7014],\n",
       "         [0.0000]]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3023,  0.4439]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1070,  0.2071]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3023,  0.4439]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â–³ Since there's no such argument as seqlens in pytorch, a trick was used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-directional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. no padding\n",
    "model1 = Rnn(bidirectional=True)\n",
    "outputs1, last_hidden1 = model1(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. zero padding without seqlens\n",
    "model2 = Rnn(bidirectional=True)\n",
    "for p1, p2 in zip(model1.parameters(), model2.parameters()):\n",
    "    p2.data = p1.data\n",
    "outputs2, last_hidden2 = model2(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. zero padding with explicit seqlens\n",
    "model3 = Rnn(bidirectional=True)\n",
    "for p1, p3 in zip(model1.parameters(), model3.parameters()):\n",
    "    p3.data = p1.data\n",
    "outputs3, last_hidden3 = model3(x2, seqlens=[3,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5312, -0.4415],\n",
       "         [ 0.0176,  0.1163],\n",
       "         [ 0.2241,  0.0834]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5312, -0.5033],\n",
       "         [ 0.0176, -0.0370],\n",
       "         [ 0.2241, -0.1416],\n",
       "         [-0.3388, -0.3100]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5312, -0.4415],\n",
       "         [ 0.0176,  0.1163],\n",
       "         [ 0.2241,  0.0834],\n",
       "         [ 0.0000,  0.0000]]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2241, -0.4415]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3388, -0.5033]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2241, -0.4415]], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â–³ Same here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
