# NLP Made Easy

Try to explain NLP building blocks in a simpler manner.

* [Subword Segmentation Techniques](Subword%20Segmentation%20Techniques.ipynb)
  * Let's compare various tokenizers, i.e., nltk, BPE, SentencePiece, and Bert tokenizer.
* [Beam decode](Beam_decode.ipynb)
* [How to get the last hidden vector of rnns properly](How%20to%20get%20the%20last%20hidden%20vector%20of%20rnns%20properly.ipynb)
* [Tensorflow seq2seq template based on the g2p task](Tensorflow%20seq2seq%20template%20based%20on%20g2p.ipynb)
* [PyTorch seq2seq template based on the g2p task](Work in progress)
* [Attention mechanism](Work in progress)
* [POS-tagging with BERT Fine-tuning](Pos-tagging_with_Bert_Fine-tuning.ipynb)
  * Bert is known to be good at Named Entity Recognition. Let's see if it's true for POS-tagging.
* [Dropout in a minute](Dropout_in_a_minute.ipynb)
  * Dropout is arguably the most popular regularization technique in deep learning. Let's check again how it work.
* Ngram LM vs. rnnlm(WIP)
