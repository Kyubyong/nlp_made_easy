{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rico Sennrich, Barry Haddow and Alexandra Birch (2016): Neural Machine Translation of Rare Words with Subword Units Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin, Germany.\n",
    "\n",
    "\"Byte Pair Encoding (BPE) (Gage, 1994) is a simple data compression technique that iteratively replaces  the  most  frequent  pair  of  bytes  in  a  sequence with a single, unused byte.  We adapt this algorithm for word segmentation. Instead of merging frequent pairs of bytes, we merge characters or\n",
    "character sequence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/rsennrich/subword-nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install subword-nmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's play a little with a toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "lower\n",
      "lower\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "widest\n",
      "widest\n",
      "widest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's create a sample text\n",
    "text =\"low\\n\"*5 + \"lower\\n\"*2 + \"newest\\n\"*6 + \"widest\\n\"*3\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('toy', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1. Learn bpe  \n",
    "Process byte pair encoding and generate merge operations, i.e., codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that -s means number of operations\n",
    "learn_bpe = \"subword-nmt learn-bpe -s 1 --min-frequency 2 < toy > codes\"\n",
    "os.system(learn_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==codes==\n",
      "#version: 0.2\n",
      "s t</w>\n",
      "====\n",
      "number of codes:  1\n"
     ]
    }
   ],
   "source": [
    "codes = open('codes', 'r').read()\n",
    "print(\"==codes==\\n\" + codes + \"====\")\n",
    "print(\"number of codes: \", len(codes.splitlines())-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "△ Check the toy sample carefully. The last 9 words end in `st`, which is most frequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2. Apply bpe  \n",
    "Apply codes to the designated file such that the original text is segmented.\n",
    "For demo, we apply the codes to the same toy file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_bpe = \"subword-nmt apply-bpe -c codes < toy > bpe\"\n",
    "os.system(apply_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==segmented==\n",
      "l@@ o@@ w\n",
      "l@@ o@@ w\n",
      "l@@ o@@ w\n",
      "l@@ o@@ w\n",
      "l@@ o@@ w\n",
      "l@@ o@@ w@@ e@@ r\n",
      "l@@ o@@ w@@ e@@ r\n",
      "n@@ e@@ w@@ e@@ st\n",
      "n@@ e@@ w@@ e@@ st\n",
      "n@@ e@@ w@@ e@@ st\n",
      "n@@ e@@ w@@ e@@ st\n",
      "n@@ e@@ w@@ e@@ st\n",
      "n@@ e@@ w@@ e@@ st\n",
      "w@@ i@@ d@@ e@@ st\n",
      "w@@ i@@ d@@ e@@ st\n",
      "w@@ i@@ d@@ e@@ st\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "bpe = open('bpe', 'r').read()\n",
    "print(\"==segmented==\\n\" + bpe + \"====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "△ Note that only `st` is glued."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 3. Get vocab. \n",
    "We get vocabulary from the segmented file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocab = \"subword-nmt get-vocab < bpe > vocab\"\n",
    "os.system(get_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==vocab==\n",
      "e@@ 17\n",
      "w@@ 11\n",
      "st 9\n",
      "l@@ 7\n",
      "o@@ 7\n",
      "n@@ 6\n",
      "w 5\n",
      "i@@ 3\n",
      "d@@ 3\n",
      "r 2\n",
      "====\n",
      "number of vocab:  10\n"
     ]
    }
   ],
   "source": [
    "vocab = open('vocab', 'r').read()\n",
    "print(\"==vocab==\\n\" + vocab + \"====\")\n",
    "print(\"number of vocab: \", len(vocab.splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "△ Note that # codes (=1) is not the same as # vocab (=10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if we increase the number of operations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==codes==\n",
      "#version: 0.2\n",
      "s t</w>\n",
      "e st</w>\n",
      "l o\n",
      "w est</w>\n",
      "n e\n",
      "ne west</w>\n",
      "lo w</w>\n",
      "w i\n",
      "wi d\n",
      "wid est</w>\n",
      "====\n",
      "number of codes:  10\n",
      "\n",
      "==segmented==\n",
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "lo@@ w@@ e@@ r\n",
      "lo@@ w@@ e@@ r\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "widest\n",
      "widest\n",
      "widest\n",
      "====\n",
      "\n",
      "==vocab==\n",
      "newest 6\n",
      "low 5\n",
      "widest 3\n",
      "lo@@ 2\n",
      "w@@ 2\n",
      "e@@ 2\n",
      "r 2\n",
      "====\n",
      "number of vocab:  7\n"
     ]
    }
   ],
   "source": [
    "learn_bpe = \"subword-nmt learn-bpe -s 10 --min-frequency 2 < toy > codes\"\n",
    "os.system(learn_bpe)\n",
    "codes = open('codes', 'r').read()\n",
    "print(\"==codes==\\n\" + codes + \"====\")\n",
    "print(\"number of codes: \", len(codes.splitlines())-1)\n",
    "\n",
    "apply_bpe = \"subword-nmt apply-bpe -c codes < toy > bpe\"\n",
    "os.system(apply_bpe)\n",
    "bpe = open('bpe', 'r').read()\n",
    "print(\"\\n==segmented==\\n\" + bpe + \"====\")\n",
    "\n",
    "get_vocab = \"subword-nmt get-vocab < bpe > vocab\"\n",
    "os.system(get_vocab)\n",
    "vocab = open('vocab', 'r').read()\n",
    "print(\"\\n==vocab==\\n\" + vocab + \"====\")\n",
    "print(\"number of vocab: \", len(vocab.splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "△ As you've seen, if you increase the number of operations,   \n",
    "words should be less segmented,\n",
    "and the number of vocabulary should decrease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to restore the original text from the segmented one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "lower\n",
      "lower\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "widest\n",
      "widest\n",
      "widest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restored = re.sub(\"@@( |$)\", \"\", bpe)\n",
    "print(restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to restrict vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reapply_bpe = \"subword-nmt apply-bpe -c codes --vocabulary vocab --vocabulary-threshold 5 < toy > bpe2\"\n",
    "os.system(reapply_bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "l@@ o@@ w@@ e@@ r\n",
      "l@@ o@@ w@@ e@@ r\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "w@@ i@@ d@@ e@@ s@@ t\n",
      "w@@ i@@ d@@ e@@ s@@ t\n",
      "w@@ i@@ d@@ e@@ s@@ t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bpe2 = open('bpe2', 'r').read()\n",
    "print(bpe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "low\n",
      "lo@@ w@@ e@@ r\n",
      "lo@@ w@@ e@@ r\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "newest\n",
      "widest\n",
      "widest\n",
      "widest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To compare with the original bpe segmented result, print it again.\n",
    "print(bpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "△ `widest`, which was not segmented, is segmented into `w@@ i@@ d@@ e@@ s@@ t` because the frequency of `widest` was less than 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful that the original vocabulary or thresholded one doesn't hold any more. We need to get the final vocabulary now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vocab = \"subword-nmt get-vocab < bpe2 > vocab2\"\n",
    "os.system(get_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newest 6\n",
      "low 5\n",
      "w@@ 5\n",
      "e@@ 5\n",
      "i@@ 3\n",
      "d@@ 3\n",
      "s@@ 3\n",
      "t 3\n",
      "l@@ 2\n",
      "o@@ 2\n",
      "r 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab2 = open(\"vocab2\", 'r').read()\n",
    "print(vocab2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test with a bigger text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download a sample file for demonstration from subword-nmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download = \"wget https://github.com/rsennrich/subword-nmt/raw/master/subword_nmt/tests/data/corpus.en\"\n",
    "os.system(download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould .\n",
      "iron cement protects the ingot against the hot , abrasive steel casting process .\n",
      "a fire restant repair cement for fire places , ovens , open fireplaces etc .\n",
      "construction and repair of highways and ...\n",
      "an announcement must be commercial character .\n",
      "goods and services advancement through the P.O.Box system is NOT ALLOWED .\n",
      "deliveries ( spam ) and other improper information deleted .\n",
      "translator Internet is a Toolbar for MS Internet Explorer .\n",
      "it allows you to translate in real time any web pasge from one language to another .\n",
      "you only have to select languages and TI does all the work for you ! automatic dictionary updates ....\n",
      "this software is written in order to increase your English keyboard typing speed , through teaching the basics of how to put your hand on to the keyboard and give some training examples .\n",
      "each lesson teaches some extra k\n"
     ]
    }
   ],
   "source": [
    "print(open('corpus.en', 'r').read()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==codes==\n",
      "#version: 0.2\n",
      "t h\n",
      "th e</w>\n",
      "i n\n",
      "a n\n",
      "e r\n",
      "r e\n",
      "o r\n",
      "a r\n",
      "t i\n",
      "an d</w>\n",
      "o f</w>\n",
      "e n\n",
      "o u\n",
      "o n\n",
      "t o</w>\n",
      "o n</w>\n",
      "====\n",
      "number of codes:  1000\n",
      "\n",
      "==segmented==\n",
      "ir@@ on c@@ ement is a read@@ y for use pa@@ st@@ e which is la@@ id as a fil@@ let by pu@@ t@@ ty k====\n",
      "\n",
      "==vocab==\n",
      "the 1358\n",
      ", 1291\n",
      ". 968\n",
      "and 663\n",
      "of 651\n",
      "a 623\n",
      "in 506\n",
      "to 490\n",
      "is 351\n",
      "ed 279\n",
      "s@@ 258\n",
      "c@@ 254\n",
      "you 253\n",
      "for 2====\n",
      "number of vocab:  1120\n"
     ]
    }
   ],
   "source": [
    "learn_bpe = \"subword-nmt learn-bpe -s 1000 --min-frequency 2 < corpus.en > codes\"\n",
    "os.system(learn_bpe)\n",
    "codes = open('codes', 'r').read()\n",
    "print(\"==codes==\\n\" + codes[:100] + \"====\")\n",
    "print(\"number of codes: \", len(codes.splitlines())-1)\n",
    "\n",
    "apply_bpe = \"subword-nmt apply-bpe -c codes < corpus.en > bpe\"\n",
    "os.system(apply_bpe)\n",
    "bpe = open('bpe', 'r').read()\n",
    "print(\"\\n==segmented==\\n\" + bpe[:100] + \"====\")\n",
    "\n",
    "get_vocab = \"subword-nmt get-vocab < bpe > vocab\"\n",
    "os.system(get_vocab)\n",
    "vocab = open('vocab', 'r').read()\n",
    "print(\"\\n==vocab==\\n\" + vocab[:100] + \"====\")\n",
    "print(\"number of vocab: \", len(vocab.splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (BPE in) SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install sentencepiece\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 1. Train.\n",
    "This should generate `m.model` and `m.vocab`. This is analogous to the `learn bpe` in `subword-nmt`. However, unlike `subword-nmt`, vocabulary, not merge operations, is fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = '--input=corpus.en --model_prefix=m --vocab_size=1000 --model_type=bpe'\n",
    "spm.SentencePieceTrainer.Train(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the vocab file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==vocab==\n",
      "<unk>\t0\n",
      "<s>\t0\n",
      "</s>\t0\n",
      "▁t\t-0\n",
      "▁a\t-1\n",
      "▁th\t-2\n",
      "in\t-3\n",
      "▁the\t-4\n",
      "er\t-5\n",
      "▁o\t-6\n",
      "re\t-7\n",
      "▁,\t-8\n",
      "▁s\t-9\n",
      "at\t-10\n",
      "nd\t-11\n",
      "▁.\n",
      "====\n",
      "number of vocab:  1000\n"
     ]
    }
   ],
   "source": [
    "vocab = open('m.vocab', 'r').read()\n",
    "print(\"\\n==vocab==\\n\" + vocab[:100] + \"\\n====\")\n",
    "print(\"number of vocab: \", len(vocab.splitlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "step 2. Encode. \n",
    "First load the trained model and segment the designated text file so that all the pieces in the vocabulary should be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'ir', 'on', '▁c', 'e', 'ment', '▁is', '▁a', '▁read', 'y', '▁for', '▁use', '▁p', 'ast', 'e', '▁which', '▁is', '▁la', 'id', '▁as', '▁a', '▁f', 'ill', 'et', '▁by', '▁p', 'ut', 't', 'y', '▁kn', 'ife', '▁or', '▁f', 'ing', 'er', '▁in', '▁the', '▁m', 'ould', '▁', 'ed', 'g', 'es', '▁(', '▁cor', 'n', 'ers', '▁)', '▁of', '▁the', '▁st', 'e', 'el', '▁in', 'g', 'ot', '▁m', 'ould', '▁.', '▁', 'ir', 'on', '▁c', 'e', 'ment', '▁pr', 'ot', 'ect', 's', '▁the', '▁in', 'g', 'ot', '▁ag', 'ain', 'st', '▁the', '▁hot', '▁,', '▁ab', 'r', 'as', 'ive', '▁st', 'e', 'el', '▁c', 'ast', 'ing', '▁process', '▁.', '▁a', '▁f', 'ire', '▁rest', 'ant', '▁rep', 'a', 'ir', '▁c']\n",
      "[923, 92, 20, 18, 924, 115, 55, 4, 596, 940, 59, 362, 28, 202, 924, 173, 55, 431, 112, 97, 4, 22, 126, 58, 158, 28, 61, 925, 940, 353, 654, 119, 22, 31, 8, 30, 7, 33, 204, 923, 27, 941, 26, 146, 888, 929, 102, 150, 29, 7, 124, 924, 60, 30, 941, 46, 33, 204, 15, 923, 92, 20, 18, 924, 115, 94, 46, 186, 930, 7, 30, 941, 46, 586, 138, 73, 7, 834, 11, 279, 931, 47, 196, 124, 924, 60, 18, 202, 31, 813, 15, 4, 22, 441, 621, 192, 449, 927, 92, 18]\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"m.model\")\n",
    "\n",
    "# Segment\n",
    "input_text = open('corpus.en', 'r').read()\n",
    "pieces = sp.EncodeAsPieces(input_text)\n",
    "ids = sp.EncodeAsIds(input_text)\n",
    "print(pieces[:100])\n",
    "print(ids[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to restore?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould . iron cement protects the ingot against the hot , abrasive steel casting process . a fire restant repair c'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodePieces(pieces[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iron cement is a ready for use paste which is laid as a fillet by putty knife or finger in the mould edges ( corners ) of the steel ingot mould . iron cement protects the ingot against the hot , abrasive steel casting process . a fire restant repair c'"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.DecodeIds(ids[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip install pytorch_pretrained_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = open(\"corpus.en\", \"r\").read()\n",
    "pieces = tokenizer.tokenize(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4157"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(pieces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\"\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n",
      ")\n",
      "*\n",
      "+\n",
      ",\n",
      "-\n",
      ".\n",
      "/\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      ":\n",
      ";\n",
      "<\n",
      "=\n",
      ">\n",
      "?\n",
      "@\n",
      "[\n",
      "\\\n",
      "]\n",
      "^\n",
      "_\n",
      "`\n",
      "{\n",
      "|\n",
      "}\n",
      "~\n",
      "¡\n",
      "¢\n",
      "£\n",
      "¥\n",
      "§\n",
      "¨\n",
      "©\n",
      "«\n",
      "¬\n",
      "®\n",
      "°\n",
      "±\n",
      "²\n",
      "³\n",
      "´\n",
      "µ\n",
      "¶\n",
      "·\n",
      "¹\n",
      "»\n",
      "¼\n",
      "½\n",
      "¾\n",
      "¿\n",
      "×\n",
      "÷\n",
      "ʻ\n",
      "ʼ\n",
      "ʾ\n",
      "ʿ\n",
      "ˈ\n",
      "ː\n",
      "́\n",
      "̃\n",
      "̍\n",
      "̯\n",
      "͡\n",
      "Α\n",
      "Β\n",
      "Γ\n",
      "Δ\n",
      "Ε\n",
      "Η\n",
      "Θ\n",
      "Ι\n",
      "Κ\n",
      "Λ\n",
      "Μ\n",
      "Ν\n",
      "Ο\n",
      "Π\n",
      "Σ\n",
      "Τ\n",
      "Φ\n",
      "Χ\n",
      "Ψ\n",
      "Ω\n",
      "ά\n",
      "έ\n",
      "ή\n",
      "ί\n",
      "α\n",
      "β\n",
      "γ\n",
      "δ\n",
      "ε\n",
      "ζ\n",
      "η\n",
      "θ\n",
      "ι\n",
      "κ\n",
      "λ\n",
      "μ\n",
      "ν\n",
      "ξ\n",
      "ο\n",
      "π\n",
      "ρ\n",
      "ς\n",
      "σ\n",
      "τ\n",
      "υ\n",
      "φ\n",
      "χ\n",
      "ψ\n",
      "ω\n",
      "ό\n",
      "ύ\n",
      "ώ\n",
      "І\n",
      "Ј\n",
      "А\n",
      "Б\n",
      "В\n",
      "Г\n",
      "Д\n",
      "Е\n",
      "Ж\n",
      "З\n",
      "И\n",
      "К\n",
      "Л\n",
      "М\n",
      "Н\n",
      "О\n",
      "П\n",
      "Р\n",
      "С\n",
      "Т\n",
      "У\n",
      "Ф\n",
      "Х\n",
      "Ц\n",
      "Ч\n",
      "Ш\n",
      "Э\n",
      "Ю\n",
      "Я\n",
      "а\n",
      "б\n",
      "в\n",
      "г\n",
      "д\n",
      "е\n",
      "ж\n",
      "з\n",
      "и\n",
      "й\n",
      "к\n",
      "л\n",
      "м\n",
      "н\n",
      "о\n",
      "п\n",
      "р\n",
      "с\n",
      "т\n",
      "у\n",
      "ф\n",
      "х\n",
      "ц\n",
      "ч\n",
      "ш\n",
      "щ\n",
      "ъ\n",
      "ы\n",
      "ь\n",
      "э\n",
      "ю\n",
      "я\n",
      "ё\n",
      "і\n",
      "ї\n",
      "ј\n",
      "њ\n",
      "ћ\n",
      "Ա\n",
      "Հ\n",
      "ա\n",
      "ե\n",
      "ի\n",
      "կ\n",
      "մ\n",
      "յ\n",
      "ն\n",
      "ո\n",
      "ս\n",
      "տ\n",
      "ր\n",
      "ւ\n",
      "ְ\n",
      "ִ\n",
      "ֵ\n",
      "ֶ\n",
      "ַ\n",
      "ָ\n",
      "ֹ\n",
      "ּ\n",
      "א\n",
      "ב\n",
      "ג\n",
      "ד\n",
      "ה\n",
      "ו\n",
      "ז\n",
      "ח\n",
      "ט\n",
      "י\n",
      "כ\n",
      "ל\n",
      "ם\n",
      "מ\n",
      "ן\n",
      "נ\n",
      "ס\n",
      "ע\n",
      "פ\n",
      "צ\n",
      "ק\n",
      "ר\n",
      "ש\n",
      "ת\n",
      "،\n",
      "ء\n",
      "آ\n",
      "أ\n",
      "إ\n",
      "ئ\n",
      "ا\n",
      "ب\n",
      "ة\n",
      "ت\n",
      "ث\n",
      "ج\n",
      "ح\n",
      "خ\n",
      "د\n",
      "ذ\n",
      "ر\n",
      "ز\n",
      "س\n",
      "ش\n",
      "ص\n",
      "ض\n",
      "ط\n",
      "ظ\n",
      "ع\n",
      "غ\n",
      "ف\n",
      "ق\n",
      "ك\n",
      "ل\n",
      "م\n",
      "ن\n",
      "ه\n",
      "و\n",
      "ى\n",
      "ي\n",
      "َ\n",
      "ِ\n",
      "ٹ\n",
      "پ\n",
      "چ\n",
      "ک\n",
      "گ\n",
      "ہ\n",
      "ی\n",
      "ے\n",
      "ं\n",
      "आ\n",
      "क\n",
      "ग\n",
      "च\n",
      "ज\n",
      "ण\n",
      "त\n",
      "द\n",
      "ध\n",
      "न\n",
      "प\n",
      "ब\n",
      "भ\n",
      "म\n",
      "य\n",
      "र\n",
      "ल\n",
      "व\n",
      "श\n",
      "ष\n",
      "स\n",
      "ह\n",
      "ा\n",
      "ि\n",
      "ी\n",
      "ु\n",
      "े\n",
      "ो\n",
      "्\n",
      "।\n",
      "॥\n",
      "আ\n",
      "ই\n",
      "এ\n",
      "ও\n",
      "ক\n",
      "খ\n",
      "গ\n",
      "চ\n",
      "ছ\n",
      "জ\n",
      "ট\n",
      "ত\n",
      "থ\n",
      "দ\n",
      "ধ\n",
      "ন\n",
      "প\n",
      "ব\n",
      "ম\n",
      "য\n",
      "র\n",
      "ল\n",
      "শ\n",
      "স\n",
      "হ\n",
      "়\n",
      "া\n",
      "ি\n",
      "ী\n",
      "ু\n",
      "ে\n",
      "ো\n",
      "্\n",
      "য়\n",
      "க\n",
      "த\n",
      "ப\n",
      "ம\n",
      "ய\n",
      "ர\n",
      "ல\n",
      "வ\n",
      "ா\n",
      "ி\n",
      "ு\n",
      "்\n",
      "ร\n",
      "་\n",
      "ག\n",
      "ང\n",
      "ད\n",
      "ན\n",
      "བ\n",
      "མ\n",
      "ར\n",
      "ལ\n",
      "ས\n",
      "ི\n",
      "ུ\n",
      "ེ\n",
      "ོ\n",
      "ა\n",
      "ე\n",
      "ი\n",
      "ლ\n",
      "ნ\n",
      "ო\n",
      "რ\n",
      "ს\n",
      "ἀ\n",
      "ἐ\n",
      "ὁ\n",
      "ὐ\n",
      "ὰ\n",
      "ὶ\n",
      "ὸ\n",
      "ῆ\n",
      "ῖ\n",
      "ῦ\n",
      "ῶ\n",
      "‐\n",
      "‑\n",
      "‒\n",
      "–\n",
      "—\n",
      "―\n",
      "‖\n",
      "‘\n",
      "’\n",
      "‚\n",
      "“\n",
      "”\n",
      "„\n",
      "†\n",
      "‡\n",
      "•\n",
      "…\n",
      "‰\n",
      "′\n",
      "″\n",
      "⁄\n",
      "⁰\n",
      "⁴\n",
      "⁵\n",
      "⁶\n",
      "⁷\n",
      "⁸\n",
      "⁹\n",
      "⁺\n",
      "⁻\n",
      "₀\n",
      "₁\n",
      "₂\n",
      "₃\n",
      "₄\n",
      "₅\n",
      "₆\n",
      "₇\n",
      "₈\n",
      "₉\n",
      "₊\n",
      "₍\n",
      "₎\n",
      "₤\n",
      "€\n",
      "₱\n",
      "₹\n",
      "ℓ\n",
      "№\n",
      "ℝ\n",
      "⅓\n",
      "←\n",
      "↑\n",
      "→\n",
      "↔\n",
      "⇌\n",
      "⇒\n",
      "∂\n",
      "∈\n",
      "−\n",
      "∗\n",
      "∘\n",
      "√\n",
      "∞\n",
      "∧\n",
      "∨\n",
      "∩\n",
      "∪\n",
      "≈\n",
      "≠\n",
      "≡\n",
      "≤\n",
      "≥\n",
      "⊂\n",
      "⊆\n",
      "⊕\n",
      "⋅\n",
      "─\n",
      "│\n",
      "■\n",
      "●\n",
      "★\n",
      "☆\n",
      "☉\n",
      "♠\n",
      "♣\n",
      "♥\n",
      "♦\n",
      "♭\n",
      "♯\n",
      "⟨\n",
      "⟩\n",
      "、\n",
      "。\n",
      "《\n",
      "》\n",
      "「\n",
      "」\n",
      "『\n",
      "』\n",
      "〜\n",
      "い\n",
      "う\n",
      "え\n",
      "お\n",
      "か\n",
      "き\n",
      "く\n",
      "け\n",
      "こ\n",
      "さ\n",
      "し\n",
      "す\n",
      "せ\n",
      "そ\n",
      "た\n",
      "ち\n",
      "つ\n",
      "て\n",
      "と\n",
      "な\n",
      "に\n",
      "の\n",
      "は\n",
      "ひ\n",
      "ま\n",
      "み\n",
      "む\n",
      "め\n",
      "も\n",
      "や\n",
      "ゆ\n",
      "よ\n",
      "ら\n",
      "り\n",
      "る\n",
      "れ\n",
      "ん\n",
      "ア\n",
      "ィ\n",
      "イ\n",
      "ウ\n",
      "エ\n",
      "オ\n",
      "カ\n",
      "ガ\n",
      "キ\n",
      "ク\n",
      "グ\n",
      "コ\n",
      "サ\n",
      "シ\n",
      "ジ\n",
      "ス\n",
      "ズ\n",
      "タ\n",
      "ダ\n",
      "ッ\n",
      "テ\n",
      "デ\n",
      "ト\n",
      "ド\n",
      "ナ\n",
      "ニ\n",
      "ハ\n",
      "バ\n",
      "パ\n",
      "フ\n",
      "ブ\n",
      "プ\n",
      "マ\n",
      "ミ\n",
      "ム\n",
      "ャ\n",
      "ュ\n",
      "ラ\n",
      "リ\n",
      "ル\n",
      "レ\n",
      "ロ\n",
      "ン\n",
      "・\n",
      "ー\n",
      "一\n",
      "三\n",
      "上\n",
      "下\n",
      "中\n",
      "事\n",
      "二\n",
      "井\n",
      "京\n",
      "人\n",
      "亻\n",
      "仁\n",
      "佐\n",
      "侍\n",
      "光\n",
      "公\n",
      "力\n",
      "北\n",
      "十\n",
      "南\n",
      "原\n",
      "口\n",
      "史\n",
      "司\n",
      "吉\n",
      "同\n",
      "和\n",
      "囗\n",
      "国\n",
      "國\n",
      "土\n",
      "城\n",
      "士\n",
      "大\n",
      "天\n",
      "太\n",
      "夫\n",
      "女\n",
      "子\n",
      "宀\n",
      "安\n",
      "宮\n",
      "宿\n",
      "小\n",
      "尚\n",
      "山\n",
      "島\n",
      "川\n",
      "州\n",
      "平\n",
      "年\n",
      "心\n",
      "愛\n",
      "戸\n",
      "文\n",
      "新\n",
      "方\n",
      "日\n",
      "明\n",
      "星\n",
      "書\n",
      "月\n",
      "木\n",
      "本\n",
      "李\n",
      "村\n",
      "東\n",
      "松\n",
      "林\n",
      "正\n",
      "武\n",
      "氏\n",
      "水\n",
      "氵\n",
      "江\n",
      "河\n",
      "海\n",
      "版\n",
      "犬\n",
      "王\n",
      "生\n",
      "田\n",
      "白\n",
      "皇\n",
      "省\n",
      "真\n",
      "石\n",
      "社\n",
      "神\n",
      "竹\n",
      "美\n",
      "義\n",
      "花\n",
      "藤\n",
      "西\n",
      "谷\n",
      "車\n",
      "辶\n",
      "道\n",
      "郎\n",
      "郡\n",
      "部\n",
      "野\n",
      "金\n",
      "長\n",
      "門\n",
      "陽\n",
      "青\n",
      "食\n",
      "馬\n",
      "高\n",
      "龍\n",
      "龸\n",
      "사\n",
      "씨\n",
      "의\n",
      "이\n",
      "한\n",
      "！\n",
      "（\n",
      "）\n",
      "，\n",
      "－\n",
      "／\n",
      "：\n",
      "...\n",
      "10\n",
      "000\n",
      "2010\n",
      "2011\n",
      "12\n",
      "2012\n",
      "2008\n",
      "2009\n",
      "2013\n",
      "2007\n",
      "2006\n",
      "2014\n",
      "15\n",
      "20\n",
      "18\n",
      "2015\n",
      "11\n",
      "2016\n",
      "##1\n",
      "30\n",
      "##2\n",
      "2005\n",
      "16\n",
      "14\n",
      "13\n",
      "##3\n",
      "2017\n",
      "25\n",
      "2004\n",
      "##4\n",
      "2000\n",
      "17\n",
      "##6\n",
      "##7\n",
      "##0\n",
      "##5\n",
      "24\n",
      "##9\n",
      "2003\n",
      "##8\n",
      "2002\n",
      "100\n",
      "21\n",
      "19\n",
      "2001\n",
      "22\n",
      "23\n",
      "1999\n",
      "28\n",
      "26\n",
      "27\n",
      "1998\n",
      "1997\n",
      "1996\n",
      "50\n",
      "29\n",
      "2018\n",
      "1995\n",
      "1994\n",
      "1992\n",
      "1993\n",
      "31\n",
      "40\n",
      "1991\n",
      "1990\n",
      "1989\n",
      "1988\n",
      "1987\n",
      "1986\n",
      "1985\n",
      "1984\n",
      "1980\n",
      "500\n",
      "1983\n",
      "1982\n",
      "1979\n",
      "1981\n",
      "200\n",
      "1972\n",
      "1976\n",
      "1978\n",
      "1974\n",
      "1975\n",
      "1977\n",
      "1970\n",
      "1968\n",
      "1973\n",
      "1945\n",
      "1971\n",
      "45\n",
      "60\n",
      "1969\n",
      "1967\n",
      "35\n",
      "65\n",
      "1964\n",
      "1966\n",
      "1965\n",
      "32\n",
      "1960\n",
      "1944\n",
      "1963\n",
      "1962\n",
      "1942\n",
      "80\n",
      "1961\n",
      "1943\n",
      "1956\n",
      "1958\n",
      "1959\n",
      "1941\n",
      "1940\n",
      "1948\n",
      "1957\n",
      "1939\n",
      "1946\n",
      "1950\n",
      "90\n",
      "33\n",
      "70\n",
      "1955\n",
      "300\n",
      "1952\n",
      "00\n",
      "1947\n",
      "44\n",
      "36\n",
      "1954\n",
      "1953\n",
      "1949\n",
      "34\n",
      "1951\n",
      "64\n",
      "38\n",
      "1938\n",
      "37\n",
      "1936\n",
      "1918\n",
      "400\n",
      "75\n",
      "1937\n",
      "42\n",
      "1935\n",
      "1920\n",
      "39\n",
      "48\n",
      "1930\n",
      "1919\n",
      "1933\n",
      "1914\n",
      "1934\n",
      "55\n",
      "1917\n",
      "41\n",
      "1929\n",
      "1928\n",
      "1932\n",
      "47\n",
      "52\n",
      "43\n",
      "1931\n",
      "49\n",
      "1927\n",
      "1922\n",
      "46\n",
      "1924\n",
      "1925\n",
      "51\n",
      "1912\n",
      "1926\n",
      "1921\n",
      "978\n",
      "1923\n",
      "1915\n",
      "1916\n",
      "1910\n",
      "150\n",
      "1913\n",
      "54\n",
      "1900\n",
      "600\n",
      "56\n",
      "1911\n",
      "53\n",
      "1908\n",
      "95\n",
      "59\n",
      "800\n",
      "58\n",
      "57\n",
      "1905\n",
      "08\n",
      "1906\n",
      "1907\n",
      "250\n",
      "1909\n",
      "99\n",
      "85\n",
      "09\n",
      "1904\n",
      "05\n",
      "07\n",
      "06\n",
      "66\n",
      "1902\n",
      "1901\n",
      "1903\n",
      "62\n",
      "98\n",
      "72\n",
      "04\n",
      "01\n",
      "96\n",
      "97\n",
      "03\n",
      "120\n",
      "1898\n",
      "88\n",
      "61\n",
      "93\n",
      "76\n",
      "67\n",
      "1899\n",
      "02\n",
      "63\n",
      "1890\n",
      "91\n",
      "92\n",
      "77\n",
      "68\n",
      "78\n",
      "81\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "700\n",
      "69\n",
      "74\n",
      "94\n",
      "71\n",
      "84\n",
      "73\n",
      "82\n",
      "1889\n",
      "89\n",
      "1893\n",
      "1892\n",
      "79\n",
      "1894\n",
      "86\n",
      "1885\n",
      "87\n",
      "1891\n",
      "83\n",
      "1888\n",
      "1000\n",
      "1864\n",
      "1865\n",
      "1880\n",
      "1887\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1886\n",
      "1870\n",
      "1884\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1878\n",
      "110\n",
      "1860\n",
      "1876\n",
      "1871\n",
      "1879\n",
      "1875\n",
      "1867\n",
      "1877\n",
      "130\n",
      "1872\n",
      "1868\n",
      "1874\n",
      "1873\n",
      "1866\n",
      "900\n",
      "##°\n",
      "1869\n",
      "101\n",
      "1850\n",
      "1848\n",
      "##00\n",
      "160\n",
      "1859\n",
      "1857\n",
      "##₂\n",
      "180\n",
      "1854\n",
      "1855\n",
      "1858\n",
      "140\n",
      "350\n",
      "1856\n",
      "125\n",
      "105\n",
      "1852\n",
      "1851\n",
      "1840\n",
      "1853\n",
      "1849\n",
      "1847\n",
      "1846\n",
      "102\n",
      "360\n",
      "1830\n",
      "1845\n",
      "104\n",
      "750\n",
      "1837\n",
      "1844\n",
      "103\n",
      "1800\n",
      "1841\n",
      "1812\n",
      "1838\n",
      "1842\n",
      "1839\n",
      "1843\n",
      "1836\n",
      "106\n",
      "1835\n",
      "1832\n",
      "450\n",
      "1500\n",
      "##а\n",
      "2019\n",
      "220\n",
      "##10\n",
      "107\n",
      "115\n",
      "1815\n",
      "1834\n",
      "108\n",
      "##²\n",
      "170\n",
      "1831\n",
      "1814\n",
      "##20\n",
      "1833\n",
      "##50\n",
      "1820\n",
      "111\n",
      "112\n",
      "240\n",
      "1825\n",
      "135\n",
      "1828\n",
      "109\n",
      "1829\n",
      "1824\n",
      "1821\n",
      "1810\n",
      "##₃\n",
      "230\n",
      "190\n",
      "##12\n",
      "128\n",
      "3000\n",
      "1826\n",
      "##₁\n",
      "1818\n",
      "113\n",
      "1813\n",
      "1822\n",
      "1827\n",
      "1816\n",
      "1793\n",
      "1801\n",
      "114\n",
      "1806\n",
      "1823\n",
      "1817\n",
      "1819\n",
      "117\n",
      "121\n",
      "2020\n",
      "1803\n",
      "##40\n",
      "1809\n",
      "175\n",
      "##⁺\n",
      "210\n",
      "116\n",
      "##30\n",
      "118\n",
      "127\n",
      "1798\n",
      "1808\n",
      "1811\n",
      "122\n",
      "1805\n",
      "123\n",
      "1804\n",
      "1794\n",
      "1807\n",
      "550\n",
      "119\n",
      "1790\n",
      "1795\n",
      "124\n",
      "1792\n",
      "280\n",
      "5000\n",
      "1802\n",
      "260\n",
      "##₄\n",
      "320\n",
      "##½\n",
      "1789\n",
      "145\n",
      "270\n",
      "650\n",
      "1799\n",
      "1796\n",
      "165\n",
      "1776\n",
      "126\n",
      "##11\n",
      "132\n",
      "1797\n",
      "155\n",
      "330\n",
      "##я\n",
      "1775\n",
      "1791\n",
      "129\n",
      "133\n",
      "£1\n",
      "131\n",
      "##18\n",
      "144\n",
      "##ه\n",
      "1200\n",
      "##α\n",
      "1600\n",
      "137\n",
      "225\n",
      "152\n",
      "138\n",
      "1780\n",
      "134\n",
      "##ي\n",
      "1783\n",
      "185\n",
      "136\n",
      "##16\n",
      "141\n",
      "##15\n",
      "##19\n",
      "##60\n",
      "1788\n",
      "850\n",
      "##17\n",
      "##о\n",
      "340\n",
      "1787\n",
      "143\n",
      "142\n",
      "##32\n",
      "##й\n",
      "##н\n",
      "1777\n",
      "##14\n",
      "501\n",
      "205\n",
      "1778\n",
      "146\n",
      "201\n",
      "##и\n",
      "370\n",
      "148\n",
      "147\n",
      "1784\n",
      "151\n",
      "##25\n",
      "1700\n",
      "##13\n",
      "139\n",
      "154\n",
      "##ن\n",
      "153\n",
      "156\n",
      "167\n",
      "1781\n",
      "202\n",
      "##ович\n",
      "1758\n",
      "1782\n",
      "168\n",
      "380\n",
      "##ς\n",
      "##د\n",
      "##21\n",
      "310\n",
      "290\n",
      "1785\n",
      "460\n",
      "256\n",
      "480\n",
      "195\n",
      "149\n",
      "##₀\n",
      "161\n",
      "157\n",
      "215\n",
      "440\n",
      "1786\n",
      "420\n",
      "1772\n",
      "275\n",
      "1774\n",
      "192\n",
      "1779\n",
      "##80\n",
      "182\n",
      "158\n",
      "1770\n",
      "235\n",
      "162\n",
      "##48\n",
      "163\n",
      "164\n",
      "##35\n",
      "1660\n",
      "375\n",
      "177\n",
      "212\n",
      "1750\n",
      "##24\n",
      "171\n",
      "172\n",
      "##е\n",
      "##³\n",
      "##ر\n",
      "1763\n",
      "208\n",
      "203\n",
      "176\n",
      "169\n",
      "181\n",
      "166\n",
      "##100\n",
      "183\n",
      "¹⁄₂\n",
      "206\n",
      "##р\n",
      "159\n",
      "##22\n",
      "222\n",
      "1760\n",
      "188\n",
      "301\n",
      "410\n",
      "##70\n",
      "211\n",
      "178\n",
      "365\n",
      "209\n",
      "173\n",
      "187\n",
      "174\n",
      "1300\n",
      "430\n",
      "##ان\n",
      "221\n",
      "186\n",
      "##45\n",
      "520\n",
      "204\n",
      "325\n",
      "184\n",
      "224\n",
      "640\n",
      "##90\n",
      "1768\n",
      "610\n",
      "207\n",
      "191\n",
      "213\n",
      "1773\n",
      "214\n",
      "194\n",
      "197\n",
      "193\n",
      "303\n",
      "911\n",
      "198\n",
      "390\n",
      "196\n",
      "##ий\n",
      "4000\n",
      "##на\n",
      "540\n",
      "216\n",
      "231\n",
      "179\n",
      "950\n",
      "217\n",
      "305\n",
      "##86\n",
      "189\n",
      "##64\n",
      "265\n",
      "219\n",
      "255\n",
      "1400\n",
      "1769\n",
      "232\n",
      "##31\n",
      "##500\n",
      "1771\n",
      "199\n",
      "218\n",
      "##23\n",
      "1765\n",
      "223\n",
      "1762\n",
      "##36\n",
      "660\n",
      "245\n",
      "226\n",
      "312\n",
      "##42\n",
      "##34\n",
      "470\n",
      "##38\n",
      "333\n",
      "560\n",
      "##46\n",
      "##33\n",
      "1761\n",
      "##ة\n",
      "1766\n",
      "1755\n",
      "1764\n",
      "227\n",
      "1767\n",
      "1640\n",
      "264\n",
      "##ν\n",
      "1759\n",
      "295\n",
      "1740\n",
      "##51\n",
      "285\n",
      "1745\n",
      "£2\n",
      "1650\n",
      "##53\n",
      "262\n",
      "234\n",
      "238\n",
      "##01\n",
      "302\n",
      "737\n",
      "1100\n",
      "##27\n",
      "233\n",
      "##28\n",
      "254\n",
      "228\n",
      "##ов\n",
      "490\n",
      "##47\n",
      "241\n",
      "##39\n",
      "1756\n",
      "246\n",
      "242\n",
      "1648\n",
      "##44\n",
      "251\n",
      "1754\n",
      "1715\n",
      "##26\n",
      "1757\n",
      "401\n",
      "1689\n",
      "229\n",
      "625\n",
      "720\n",
      "243\n",
      "252\n",
      "##55\n",
      "315\n",
      "##евич\n",
      "##−\n",
      "281\n",
      "313\n",
      "##43\n",
      "##اد\n",
      "287\n",
      "##41\n",
      "253\n",
      "1730\n",
      "425\n",
      "237\n",
      "247\n",
      "510\n",
      "1644\n",
      "##75\n",
      "##م\n",
      "530\n",
      "311\n",
      "1720\n",
      "##37\n",
      "##ος\n",
      "236\n",
      "630\n",
      "620\n",
      "249\n",
      "239\n",
      "580\n",
      "322\n",
      "345\n",
      "1753\n",
      "1710\n",
      "304\n",
      "##29\n",
      "802\n",
      "680\n",
      "316\n",
      "405\n",
      "321\n",
      "1661\n",
      "1642\n",
      "1688\n",
      "435\n",
      "##♭\n",
      "244\n",
      "272\n",
      "308\n",
      "1620\n",
      "257\n",
      "258\n",
      "512\n",
      "335\n",
      "385\n",
      "1751\n",
      "261\n",
      "1748\n",
      "1746\n",
      "1747\n",
      "307\n",
      "248\n",
      "##65\n",
      "1680\n",
      "306\n",
      "760\n",
      "395\n",
      "415\n",
      "1749\n",
      "278\n",
      "1752\n",
      "1690\n",
      "404\n",
      "288\n",
      "570\n",
      "286\n",
      "##!\n",
      "##\"\n",
      "###\n",
      "##$\n",
      "##%\n",
      "##&\n",
      "##'\n",
      "##(\n",
      "##)\n",
      "##*\n",
      "##+\n",
      "##,\n",
      "##-\n",
      "##.\n",
      "##/\n",
      "##:\n",
      "##;\n",
      "##<\n",
      "##=\n",
      "##>\n",
      "##?\n",
      "##@\n",
      "##[\n",
      "##\\\n",
      "##]\n",
      "##^\n",
      "##_\n",
      "##`\n",
      "##{\n",
      "##|\n",
      "##}\n",
      "##~\n",
      "##¡\n",
      "##¢\n",
      "##£\n",
      "##¥\n",
      "##§\n",
      "##¨\n",
      "##©\n",
      "##«\n",
      "##¬\n",
      "##®\n",
      "##±\n",
      "##´\n",
      "##µ\n",
      "##¶\n",
      "##·\n",
      "##¹\n",
      "##»\n",
      "##¼\n",
      "##¾\n",
      "##¿\n",
      "##×\n",
      "##÷\n",
      "##ʻ\n",
      "##ʼ\n",
      "##ʾ\n",
      "##ʿ\n",
      "##ˈ\n",
      "##ː\n",
      "##́\n",
      "##̃\n",
      "##̍\n",
      "##̯\n",
      "##͡\n",
      "##Α\n",
      "##Β\n",
      "##Γ\n",
      "##Δ\n",
      "##Ε\n",
      "##Η\n",
      "##Θ\n",
      "##Ι\n",
      "##Κ\n",
      "##Λ\n",
      "##Μ\n",
      "##Ν\n",
      "##Ο\n",
      "##Π\n",
      "##Σ\n",
      "##Τ\n",
      "##Φ\n",
      "##Χ\n",
      "##Ψ\n",
      "##Ω\n",
      "##ά\n",
      "##έ\n",
      "##ή\n",
      "##ί\n",
      "##β\n",
      "##γ\n",
      "##δ\n",
      "##ε\n",
      "##ζ\n",
      "##η\n",
      "##θ\n",
      "##ι\n",
      "##κ\n",
      "##λ\n",
      "##μ\n",
      "##ξ\n",
      "##ο\n",
      "##π\n",
      "##ρ\n",
      "##σ\n",
      "##τ\n",
      "##υ\n",
      "##φ\n",
      "##χ\n",
      "##ψ\n",
      "##ω\n",
      "##ό\n",
      "##ύ\n",
      "##ώ\n",
      "##І\n",
      "##Ј\n",
      "##А\n",
      "##Б\n",
      "##В\n",
      "##Г\n",
      "##Д\n",
      "##Е\n",
      "##Ж\n",
      "##З\n",
      "##И\n",
      "##К\n",
      "##Л\n",
      "##М\n",
      "##Н\n",
      "##О\n",
      "##П\n",
      "##Р\n",
      "##С\n",
      "##Т\n",
      "##У\n",
      "##Ф\n",
      "##Х\n",
      "##Ц\n",
      "##Ч\n",
      "##Ш\n",
      "##Э\n",
      "##Ю\n",
      "##Я\n",
      "##б\n",
      "##в\n",
      "##г\n",
      "##д\n",
      "##ж\n",
      "##з\n",
      "##к\n",
      "##л\n",
      "##м\n",
      "##п\n",
      "##с\n",
      "##т\n",
      "##у\n",
      "##ф\n",
      "##х\n",
      "##ц\n",
      "##ч\n",
      "##ш\n",
      "##щ\n",
      "##ъ\n",
      "##ы\n",
      "##ь\n",
      "##э\n",
      "##ю\n",
      "##ё\n",
      "##і\n",
      "##ї\n",
      "##ј\n",
      "##њ\n",
      "##ћ\n",
      "##Ա\n",
      "##Հ\n",
      "##ա\n",
      "##ե\n",
      "##ի\n",
      "##կ\n",
      "##մ\n",
      "##յ\n",
      "##ն\n",
      "##ո\n",
      "##ս\n",
      "##տ\n",
      "##ր\n",
      "##ւ\n",
      "##ְ\n",
      "##ִ\n",
      "##ֵ\n",
      "##ֶ\n",
      "##ַ\n",
      "##ָ\n",
      "##ֹ\n",
      "##ּ\n",
      "##א\n",
      "##ב\n",
      "##ג\n",
      "##ד\n",
      "##ה\n",
      "##ו\n",
      "##ז\n",
      "##ח\n",
      "##ט\n",
      "##י\n",
      "##כ\n",
      "##ל\n",
      "##ם\n",
      "##מ\n",
      "##ן\n",
      "##נ\n",
      "##ס\n",
      "##ע\n",
      "##פ\n",
      "##צ\n",
      "##ק\n",
      "##ר\n",
      "##ש\n",
      "##ת\n",
      "##،\n",
      "##ء\n",
      "##آ\n",
      "##أ\n",
      "##إ\n",
      "##ئ\n",
      "##ا\n",
      "##ب\n",
      "##ت\n",
      "##ث\n",
      "##ج\n",
      "##ح\n",
      "##خ\n",
      "##ذ\n",
      "##ز\n",
      "##س\n",
      "##ش\n",
      "##ص\n",
      "##ض\n",
      "##ط\n",
      "##ظ\n",
      "##ع\n",
      "##غ\n",
      "##ف\n",
      "##ق\n",
      "##ك\n",
      "##ل\n",
      "##و\n",
      "##ى\n",
      "##َ\n",
      "##ِ\n",
      "##ٹ\n",
      "##پ\n",
      "##چ\n",
      "##ک\n",
      "##گ\n",
      "##ہ\n",
      "##ی\n",
      "##ے\n",
      "##ं\n",
      "##आ\n",
      "##क\n",
      "##ग\n",
      "##च\n",
      "##ज\n",
      "##ण\n",
      "##त\n",
      "##द\n",
      "##ध\n",
      "##न\n",
      "##प\n",
      "##ब\n",
      "##भ\n",
      "##म\n",
      "##य\n",
      "##र\n",
      "##ल\n",
      "##व\n",
      "##श\n",
      "##ष\n",
      "##स\n",
      "##ह\n",
      "##ा\n",
      "##ि\n",
      "##ी\n",
      "##ु\n",
      "##े\n",
      "##ो\n",
      "##्\n",
      "##।\n",
      "##॥\n",
      "##আ\n",
      "##ই\n",
      "##এ\n",
      "##ও\n",
      "##ক\n",
      "##খ\n",
      "##গ\n",
      "##চ\n",
      "##ছ\n",
      "##জ\n",
      "##ট\n",
      "##ত\n",
      "##থ\n",
      "##দ\n",
      "##ধ\n",
      "##ন\n",
      "##প\n",
      "##ব\n",
      "##ম\n",
      "##য\n",
      "##র\n",
      "##ল\n",
      "##শ\n",
      "##স\n",
      "##হ\n",
      "##়\n",
      "##া\n",
      "##ি\n",
      "##ী\n",
      "##ু\n",
      "##ে\n",
      "##ো\n",
      "##্\n",
      "##য়\n",
      "##க\n",
      "##த\n",
      "##ப\n",
      "##ம\n",
      "##ய\n",
      "##ர\n",
      "##ல\n",
      "##வ\n",
      "##ா\n",
      "##ி\n",
      "##ு\n",
      "##்\n",
      "##ร\n",
      "##་\n",
      "##ག\n",
      "##ང\n",
      "##ད\n",
      "##ན\n",
      "##བ\n",
      "##མ\n",
      "##ར\n",
      "##ལ\n",
      "##ས\n",
      "##ི\n",
      "##ུ\n",
      "##ེ\n",
      "##ོ\n",
      "##ა\n",
      "##ე\n",
      "##ი\n",
      "##ლ\n",
      "##ნ\n",
      "##ო\n",
      "##რ\n",
      "##ს\n",
      "##ἀ\n",
      "##ἐ\n",
      "##ὁ\n",
      "##ὐ\n",
      "##ὰ\n",
      "##ὶ\n",
      "##ὸ\n",
      "##ῆ\n",
      "##ῖ\n",
      "##ῦ\n",
      "##ῶ\n",
      "##‐\n",
      "##‑\n",
      "##‒\n",
      "##–\n",
      "##—\n",
      "##―\n",
      "##‖\n",
      "##‘\n",
      "##’\n",
      "##‚\n",
      "##“\n",
      "##”\n",
      "##„\n",
      "##†\n",
      "##‡\n",
      "##•\n",
      "##…\n",
      "##‰\n",
      "##′\n",
      "##″\n",
      "##⁄\n",
      "##⁰\n",
      "##⁴\n",
      "##⁵\n",
      "##⁶\n",
      "##⁷\n",
      "##⁸\n",
      "##⁹\n",
      "##⁻\n",
      "##₅\n",
      "##₆\n",
      "##₇\n",
      "##₈\n",
      "##₉\n",
      "##₊\n",
      "##₍\n",
      "##₎\n",
      "##₤\n",
      "##€\n",
      "##₱\n",
      "##₹\n",
      "##ℓ\n",
      "##№\n",
      "##ℝ\n",
      "##⅓\n",
      "##←\n",
      "##↑\n",
      "##→\n",
      "##↔\n",
      "##⇌\n",
      "##⇒\n",
      "##∂\n",
      "##∈\n",
      "##∗\n",
      "##∘\n",
      "##√\n",
      "##∞\n",
      "##∧\n",
      "##∨\n",
      "##∩\n",
      "##∪\n",
      "##≈\n",
      "##≠\n",
      "##≡\n",
      "##≤\n",
      "##≥\n",
      "##⊂\n",
      "##⊆\n",
      "##⊕\n",
      "##⋅\n",
      "##─\n",
      "##│\n",
      "##■\n",
      "##●\n",
      "##★\n",
      "##☆\n",
      "##☉\n",
      "##♠\n",
      "##♣\n",
      "##♥\n",
      "##♦\n",
      "##♯\n",
      "##⟨\n",
      "##⟩\n",
      "##、\n",
      "##。\n",
      "##《\n",
      "##》\n",
      "##「\n",
      "##」\n",
      "##『\n",
      "##』\n",
      "##〜\n",
      "##い\n",
      "##う\n",
      "##え\n",
      "##お\n",
      "##か\n",
      "##き\n",
      "##く\n",
      "##け\n",
      "##こ\n",
      "##さ\n",
      "##し\n",
      "##す\n",
      "##せ\n",
      "##そ\n",
      "##た\n",
      "##ち\n",
      "##つ\n",
      "##て\n",
      "##と\n",
      "##な\n",
      "##に\n",
      "##の\n",
      "##は\n",
      "##ひ\n",
      "##ま\n",
      "##み\n",
      "##む\n",
      "##め\n",
      "##も\n",
      "##や\n",
      "##ゆ\n",
      "##よ\n",
      "##ら\n",
      "##り\n",
      "##る\n",
      "##れ\n",
      "##ん\n",
      "##ア\n",
      "##ィ\n",
      "##イ\n",
      "##ウ\n",
      "##エ\n",
      "##オ\n",
      "##カ\n",
      "##ガ\n",
      "##キ\n",
      "##ク\n",
      "##グ\n",
      "##コ\n",
      "##サ\n",
      "##シ\n",
      "##ジ\n",
      "##ス\n",
      "##ズ\n",
      "##タ\n",
      "##ダ\n",
      "##ッ\n",
      "##テ\n",
      "##デ\n",
      "##ト\n",
      "##ド\n",
      "##ナ\n",
      "##ニ\n",
      "##ハ\n",
      "##バ\n",
      "##パ\n",
      "##フ\n",
      "##ブ\n",
      "##プ\n",
      "##マ\n",
      "##ミ\n",
      "##ム\n",
      "##ャ\n",
      "##ュ\n",
      "##ラ\n",
      "##リ\n",
      "##ル\n",
      "##レ\n",
      "##ロ\n",
      "##ン\n",
      "##・\n",
      "##ー\n",
      "##一\n",
      "##三\n",
      "##上\n",
      "##下\n",
      "##中\n",
      "##事\n",
      "##二\n",
      "##井\n",
      "##京\n",
      "##人\n",
      "##亻\n",
      "##仁\n",
      "##佐\n",
      "##侍\n",
      "##光\n",
      "##公\n",
      "##力\n",
      "##北\n",
      "##十\n",
      "##南\n",
      "##原\n",
      "##口\n",
      "##史\n",
      "##司\n",
      "##吉\n",
      "##同\n",
      "##和\n",
      "##囗\n",
      "##国\n",
      "##國\n",
      "##土\n",
      "##城\n",
      "##士\n",
      "##大\n",
      "##天\n",
      "##太\n",
      "##夫\n",
      "##女\n",
      "##子\n",
      "##宀\n",
      "##安\n",
      "##宮\n",
      "##宿\n",
      "##小\n",
      "##尚\n",
      "##山\n",
      "##島\n",
      "##川\n",
      "##州\n",
      "##平\n",
      "##年\n",
      "##心\n",
      "##愛\n",
      "##戸\n",
      "##文\n",
      "##新\n",
      "##方\n",
      "##日\n",
      "##明\n",
      "##星\n",
      "##書\n",
      "##月\n",
      "##木\n",
      "##本\n",
      "##李\n",
      "##村\n",
      "##東\n",
      "##松\n",
      "##林\n",
      "##正\n",
      "##武\n",
      "##氏\n",
      "##水\n",
      "##氵\n",
      "##江\n",
      "##河\n",
      "##海\n",
      "##版\n",
      "##犬\n",
      "##王\n",
      "##生\n",
      "##田\n",
      "##白\n",
      "##皇\n",
      "##省\n",
      "##真\n",
      "##石\n",
      "##社\n",
      "##神\n",
      "##竹\n",
      "##美\n",
      "##義\n",
      "##花\n",
      "##藤\n",
      "##西\n",
      "##谷\n",
      "##車\n",
      "##辶\n",
      "##道\n",
      "##郎\n",
      "##郡\n",
      "##部\n",
      "##野\n",
      "##金\n",
      "##長\n",
      "##門\n",
      "##陽\n",
      "##青\n",
      "##食\n",
      "##馬\n",
      "##高\n",
      "##龍\n",
      "##龸\n",
      "##사\n",
      "##씨\n",
      "##의\n",
      "##이\n",
      "##한\n",
      "##！\n",
      "##（\n",
      "##）\n",
      "##，\n",
      "##－\n",
      "##／\n",
      "##：\n"
     ]
    }
   ],
   "source": [
    "for k in tokenizer.vocab:\n",
    "    if regex.search(\"\\p{Latin}\", k) is None:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
