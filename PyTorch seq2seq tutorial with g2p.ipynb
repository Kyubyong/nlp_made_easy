{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll write a simple template for seq2seq using PyTorch. For demonstration, we attack the g2p task. G2p is a task of converting graphemes (spelling) to phonemes (pronunciation). It's a very good source for this purpose as it's simple enough for you to up and run. If you want to know more about g2p, see my repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"kyubyong\"\n",
    "__address__ = \"https://github.com/kyubyong/nlp_made_easy\"\n",
    "__email__ = \"kbpark.linguist@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEXqpZ_U738q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=1000)\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from distance import levenshtein\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_7vuctbU7381",
    "outputId": "f8ee2cbf-1f04-432f-ba42-d25fec61669b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B6te4HKk738_"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWS2hkce739C"
   },
   "outputs": [],
   "source": [
    "class Hparams:\n",
    "    batch_size = 128\n",
    "    enc_maxlen = 20\n",
    "    dec_maxlen = 20\n",
    "    num_epochs = 10\n",
    "    hidden_units = 128\n",
    "    graphemes = [\"<pad>\", \"<unk>\", \"</s>\"] + list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "    phonemes = [\"<pad>\", \"<unk>\", \"<s>\", \"</s>\"] + ['AA0', 'AA1', 'AA2', 'AE0', 'AE1', 'AE2', 'AH0', 'AH1', 'AH2', 'AO0',\n",
    "                    'AO1', 'AO2', 'AW0', 'AW1', 'AW2', 'AY0', 'AY1', 'AY2', 'B', 'CH', 'D', 'DH',\n",
    "                    'EH0', 'EH1', 'EH2', 'ER0', 'ER1', 'ER2', 'EY0', 'EY1', 'EY2', 'F', 'G', 'HH',\n",
    "                    'IH0', 'IH1', 'IH2', 'IY0', 'IY1', 'IY2', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW0', 'OW1',\n",
    "                    'OW2', 'OY0', 'OY1', 'OY2', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH0', 'UH1', 'UH2', 'UW',\n",
    "                    'UW0', 'UW1', 'UW2', 'V', 'W', 'Y', 'Z', 'ZH']\n",
    "    lr = 0.001\n",
    "    logdir = \"log/04\"\n",
    "hp = Hparams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nz-hD6dn739L"
   },
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-as4PHs-739N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['R', 'AH0', 'F', 'Y', 'UW1', 'Z'],\n",
       " ['R', 'EH1', 'F', 'Y', 'UW2', 'Z'],\n",
       " ['R', 'IH0', 'F', 'Y', 'UW1', 'Z']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download('cmudict')# <- if you haven't downloaded, do this.\n",
    "from nltk.corpus import cmudict\n",
    "cmu = cmudict.dict()\n",
    "cmu[\"refuse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "39gQ3vOi739S"
   },
   "outputs": [],
   "source": [
    "def load_vocab():\n",
    "    g2idx = {g: idx for idx, g in enumerate(hp.graphemes)}\n",
    "    idx2g = {idx: g for idx, g in enumerate(hp.graphemes)}\n",
    "\n",
    "    p2idx = {p: idx for idx, p in enumerate(hp.phonemes)}\n",
    "    idx2p = {idx: p for idx, p in enumerate(hp.phonemes)}\n",
    "\n",
    "    return g2idx, idx2g, p2idx, idx2p # note that g and p mean grapheme and phoneme, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zslytxn6739Z"
   },
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    words = [\" \".join(list(word)) for word, prons in cmu.items()]\n",
    "    prons = [\" \".join(prons[0]) for word, prons in cmu.items()]\n",
    "    indices = list(range(len(words)))\n",
    "    from random import shuffle\n",
    "    shuffle(indices)\n",
    "    words = [words[idx] for idx in indices]\n",
    "    prons = [prons[idx] for idx in indices]\n",
    "    num_train, num_test = int(len(words)*.8), int(len(words)*.1)\n",
    "    train_words, eval_words, test_words = words[:num_train], \\\n",
    "                                          words[num_train:-num_test],\\\n",
    "                                          words[-num_test:]\n",
    "    train_prons, eval_prons, test_prons = prons[:num_train], \\\n",
    "                                          prons[num_train:-num_test],\\\n",
    "                                          prons[-num_test:]    \n",
    "    return train_words, eval_words, test_words, train_prons, eval_prons, test_prons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WHBXkAPG739j"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i n d o n e s i a ' s\n",
      "IH2 N D OW0 N IY1 ZH AH0 Z\n"
     ]
    }
   ],
   "source": [
    "train_words, eval_words, test_words, train_prons, eval_prons, test_prons = prepare_data()\n",
    "print(train_words[0])\n",
    "print(train_prons[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_lengthy_samples(words, prons, enc_maxlen, dec_maxlen):\n",
    "    \"\"\"We only include such samples less than maxlen.\"\"\"\n",
    "    _words, _prons = [], []\n",
    "    for w, p in zip(words, prons):\n",
    "        if len(w.split()) + 1 > enc_maxlen: continue\n",
    "        if len(p.split()) + 1 > dec_maxlen: continue # 1: <EOS>\n",
    "        _words.append(w)\n",
    "        _prons.append(p)\n",
    "    return _words, _prons          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words, train_prons = drop_lengthy_samples(train_words, train_prons, hp.enc_maxlen, hp.dec_maxlen)\n",
    "# We do NOT apply this constraint to eval and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(inp, type, dict):\n",
    "    '''type: \"x\" or \"y\"'''\n",
    "#     inp_str = inp.decode(\"utf-8\")\n",
    "    if type==\"x\": tokens = inp.split() + [\"</s>\"]\n",
    "    else: tokens = [\"<s>\"] + inp.split() + [\"</s>\"]\n",
    "\n",
    "    x = [dict.get(t, dict[\"<unk>\"]) for t in tokens]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class G2pDataset(Dataset):\n",
    "\n",
    "    def __init__(self, words, prons):\n",
    "        \"\"\"\n",
    "        words: list of words. e.g., [\"word\", ]\n",
    "        prons: list of prons. e.g., ['W ER1 D',]\n",
    "        maxlen: scalar.\n",
    "        \"\"\"\n",
    "        self.words = words\n",
    "        self.prons = prons\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.words)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        g2idx, idx2g, p2idx, idx2p = load_vocab()\n",
    "        \n",
    "        word, pron = self.words[idx], self.prons[idx]\n",
    "        x = encode(word, \"x\", g2idx)\n",
    "        y = encode(word, \"y\", g2idx)\n",
    "        decoder_input, y = y[:-1], y[1:]\n",
    "\n",
    "        x_seqlen, y_seqlen = len(x), len(y)\n",
    "                \n",
    "        return x, x_seqlen, word, decoder_input, y, y_seqlen, pron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = G2pDataset(train_words, train_prons)\n",
    "eval_dataset = G2pDataset(eval_words, eval_prons)\n",
    "# test_dataset = G2pDataset(test_words, test_prons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(batch):\n",
    "    '''Pads to the longest sample'''\n",
    "    f = lambda x: [sample[x] for sample in batch]\n",
    "    x_seqlens = f(1)\n",
    "    y_seqlens = f(5)\n",
    "    words = f(2)\n",
    "    prons = f(-1)\n",
    "    \n",
    "    x_maxlen = np.array(x_seqlens).max()\n",
    "    y_maxlen = np.array(y_seqlens).max()\n",
    "    \n",
    "    f = lambda x, seqlen: [sample[x]+[0]*(seqlen-len(sample[x])) for sample in batch]\n",
    "    x = f(0, x_maxlen)\n",
    "    decoder_inputs = f(3, y_maxlen)\n",
    "    y = f(4, y_maxlen)\n",
    "    \n",
    "    f = torch.IntTensor\n",
    "    return f(x), f(x_seqlens), words, f(decoder_inputs), f(y), f(y_seqlens), prons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=hp.batch_size, shuffle=True, collate_fn=trim)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=hp.batch_size, shuffle=False, collate_fn=trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = iter(train_loader)\n",
    "eval_iter = iter(eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22mif4xf73-M"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    pass\n",
    "\n",
    "class Decoder():\n",
    "    pass\n",
    "\n",
    "class Net():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HA39FU4-73-O"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-307-a1af65aec9b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg2idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx2g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp2idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midx2p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "class Net:\n",
    "    def __init__(self, params):\n",
    "        self.g2idx, self.idx2g, self.p2idx, self.idx2p = load_vocab()\n",
    "        self.params = params\n",
    "    \n",
    "    def encode(self, xs):\n",
    "        '''\n",
    "        xs: tupple of \n",
    "            x: (N, T)\n",
    "            seqlens: (N,)\n",
    "            word: (N,)\n",
    "            \n",
    "        returns last hidden state of shape (N, hidden_units)    \n",
    "        '''\n",
    "        with tf.variable_scope(\"encode\"):\n",
    "            x, seqlens, words = xs\n",
    "            x = tf.one_hot(x, len(self.g2idx))\n",
    "            cell = tf.contrib.rnn.GRUCell(self.params[\"hidden_units\"])\n",
    "            outputs, last_hidden = tf.nn.dynamic_rnn(cell, x, seqlens, dtype=tf.float32)\n",
    "        \n",
    "        return last_hidden, words\n",
    "        \n",
    "    \n",
    "    def decode(self, ys, h0=None):\n",
    "        '''\n",
    "        ys: tupple of\n",
    "            decoder_inputs: (N, T)\n",
    "            y: (N, T)\n",
    "            seqlens: (N,)\n",
    "            pron: (N,)\n",
    "            \n",
    "        returns last hidden state of shape (N, hidden_units)  \n",
    "        '''\n",
    "        decoder_inputs, y, seqlens, prons = ys\n",
    "            \n",
    "        with tf.variable_scope(\"decode\"):\n",
    "            inputs = tf.one_hot(decoder_inputs, len(self.p2idx))\n",
    "            cell = tf.contrib.rnn.GRUCell(self.params[\"hidden_units\"])\n",
    "            outputs, _ = tf.nn.dynamic_rnn(cell, inputs, initial_state=h0, dtype=tf.float32)\n",
    "\n",
    "            # projection\n",
    "            logits = tf.layers.dense(outputs, len(self.p2idx))\n",
    "            preds = tf.to_int32(tf.argmax(logits, axis=-1))\n",
    "        \n",
    "        return logits, preds, y, prons\n",
    "        \n",
    "    \n",
    "    def forward(self, xs, ys):\n",
    "        last_hidden, word = self.encode(xs)\n",
    "        logits, preds, y, prons = self.decode(ys, h0=last_hidden)\n",
    "        return word, logits, preds, y, prons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKllLnfp73-V"
   },
   "source": [
    "# Train & Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "64f3a-fb73-Y",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_batches = data.DataLoader(train_dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
    "eval_batches = data.DataLoader(eval_dataset, batch_size=params[\"batch_size\"], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iL3CK4NW73-g"
   },
   "outputs": [],
   "source": [
    "# create a iterator of the correct shape and type\n",
    "iter = tf.data.Iterator.from_structure(train_batches.output_types, eval_batches.output_shapes)\n",
    "xs, ys = iter.get_next()\n",
    "\n",
    "# create the initialisation operations\n",
    "train_init_op = iter.make_initializer(train_batches)\n",
    "eval_init_op = iter.make_initializer(eval_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "aF0cJceg73-m",
    "outputId": "ab78b80a-d6e3-4408-af21-acff58944a79",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-31-e560bc48303f>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-34-e828fb837d78>:6: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "m = Model(params)\n",
    "words, logits, preds, y, prons = m.forward(xs, ys)\n",
    "\n",
    "# train\n",
    "ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "mask = tf.to_float(tf.not_equal(y, m.p2idx[\"<PAD>\"])) # 0: <pad>\n",
    "loss = tf.reduce_sum(ce*mask) / (tf.reduce_sum(mask)+1e-7)\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "train_op = tf.train.AdamOptimizer(params[\"lr\"]).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 14303
    },
    "colab_type": "code",
    "id": "frKAWTc873-q",
    "outputId": "2d464429-3e88-4f3f-9a9d-d64094d995f9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== global step= 100 ==========\n",
      "train loss= 3.54\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: R \n",
      "\n",
      "========== global step= 200 ==========\n",
      "train loss= 3.26\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: R L L AH0 \n",
      "\n",
      "========== global step= 300 ==========\n",
      "train loss= 3.18\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: R L AH0 AH0 \n",
      "\n",
      "========== global step= 400 ==========\n",
      "train loss= 3.14\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: R L AH0 AH0 \n",
      "\n",
      "========== global step= 500 ==========\n",
      "train loss= 3.09\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: R L L AH0 \n",
      "\n",
      "========== global step= 600 ==========\n",
      "train loss= 3.04\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: R L N AH0 N \n",
      "\n",
      "========== global step= 700 ==========\n",
      "train loss= 2.99\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: S AH0 L AH0 N \n",
      "\n",
      "========== global step= 800 ==========\n",
      "train loss= 2.95\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: K AH0 L AH0 N \n",
      "\n",
      "========== global step= 900 ==========\n",
      "train loss= 2.91\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B AE1 L AH0 N \n",
      "\n",
      "========== global step= 1000 ==========\n",
      "train loss= 2.87\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B AE1 L AH0 N \n",
      "\n",
      "========== global step= 1100 ==========\n",
      "train loss= 2.83\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B AE1 L AH0 N \n",
      "\n",
      "========== global step= 1200 ==========\n",
      "train loss= 2.79\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B AE1 L AH0 N \n",
      "\n",
      "========== global step= 1300 ==========\n",
      "train loss= 2.75\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B AE1 L AH0 N \n",
      "\n",
      "========== global step= 1400 ==========\n",
      "train loss= 2.72\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 L AH0 N \n",
      "\n",
      "========== global step= 1500 ==========\n",
      "train loss= 2.69\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 L AH0 N \n",
      "\n",
      "========== global step= 1600 ==========\n",
      "train loss= 2.67\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 L AH0 N \n",
      "\n",
      "========== global step= 1700 ==========\n",
      "train loss= 2.65\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 L AH0 N \n",
      "\n",
      "========== global step= 1800 ==========\n",
      "train loss= 2.63\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 L AH0 NG \n",
      "\n",
      "========== global step= 1900 ==========\n",
      "train loss= 2.61\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 L AH0 NG \n",
      "\n",
      "========== global step= 2000 ==========\n",
      "train loss= 2.59\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 L AH0 NG \n",
      "\n",
      "========== global step= 2100 ==========\n",
      "train loss= 2.57\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 L AH0 NG \n",
      "\n",
      "========== global step= 2200 ==========\n",
      "train loss= 2.55\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 S AH0 NG \n",
      "\n",
      "========== global step= 2300 ==========\n",
      "train loss= 2.53\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 S AH0 NG \n",
      "\n",
      "========== global step= 2400 ==========\n",
      "train loss= 2.52\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 S AH0 NG \n",
      "\n",
      "========== global step= 2500 ==========\n",
      "train loss= 2.50\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 S AH0 NG \n",
      "\n",
      "========== global step= 2600 ==========\n",
      "train loss= 2.49\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N AH0 NG \n",
      "\n",
      "========== global step= 2700 ==========\n",
      "train loss= 2.47\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N AH0 NG \n",
      "\n",
      "========== global step= 2800 ==========\n",
      "train loss= 2.46\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N AH0 NG \n",
      "\n",
      "========== global step= 2900 ==========\n",
      "train loss= 2.45\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N AH0 NG \n",
      "\n",
      "========== global step= 3000 ==========\n",
      "train loss= 2.44\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N AH0 NG \n",
      "\n",
      "========== global step= 3100 ==========\n",
      "train loss= 2.43\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N AH0 NG \n",
      "\n",
      "========== global step= 3200 ==========\n",
      "train loss= 2.42\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N AH0 NG \n",
      "\n",
      "========== global step= 3300 ==========\n",
      "train loss= 2.40\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N IH0 NG \n",
      "\n",
      "========== global step= 3400 ==========\n",
      "train loss= 2.39\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: B IH1 N IH0 NG \n",
      "\n",
      "========== global step= 3500 ==========\n",
      "train loss= 2.37\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 3600 ==========\n",
      "train loss= 2.36\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 3700 ==========\n",
      "train loss= 2.34\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 3800 ==========\n",
      "train loss= 2.33\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 3900 ==========\n",
      "train loss= 2.31\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4000 ==========\n",
      "train loss= 2.30\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4100 ==========\n",
      "train loss= 2.28\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4200 ==========\n",
      "train loss= 2.25\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4300 ==========\n",
      "train loss= 2.22\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4400 ==========\n",
      "train loss= 2.20\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4500 ==========\n",
      "train loss= 2.18\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4600 ==========\n",
      "train loss= 2.17\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4700 ==========\n",
      "train loss= 2.16\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4800 ==========\n",
      "train loss= 2.15\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 4900 ==========\n",
      "train loss= 2.14\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5000 ==========\n",
      "train loss= 2.14\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5100 ==========\n",
      "train loss= 2.14\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5200 ==========\n",
      "train loss= 2.13\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5300 ==========\n",
      "train loss= 2.13\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5400 ==========\n",
      "train loss= 2.13\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5500 ==========\n",
      "train loss= 2.12\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5600 ==========\n",
      "train loss= 2.12\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5700 ==========\n",
      "train loss= 2.11\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5800 ==========\n",
      "train loss= 2.11\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 5900 ==========\n",
      "train loss= 2.10\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 N \n",
      "\n",
      "========== global step= 6000 ==========\n",
      "train loss= 2.10\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 6100 ==========\n",
      "train loss= 2.10\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 6200 ==========\n",
      "train loss= 2.09\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 6300 ==========\n",
      "train loss= 2.08\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 6400 ==========\n",
      "train loss= 2.06\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 6500 ==========\n",
      "train loss= 2.04\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 N IH0 NG \n",
      "\n",
      "========== global step= 6600 ==========\n",
      "train loss= 2.03\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 6700 ==========\n",
      "train loss= 2.01\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 6800 ==========\n",
      "train loss= 2.03\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 6900 ==========\n",
      "train loss= 2.02\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7000 ==========\n",
      "train loss= 1.98\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7100 ==========\n",
      "train loss= 1.97\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7200 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7300 ==========\n",
      "train loss= 1.93\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7400 ==========\n",
      "train loss= 1.93\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7500 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7600 ==========\n",
      "train loss= 1.95\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7700 ==========\n",
      "train loss= 1.95\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7800 ==========\n",
      "train loss= 1.95\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 7900 ==========\n",
      "train loss= 1.95\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 D IH0 NG Z \n",
      "\n",
      "========== global step= 8000 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 8100 ==========\n",
      "train loss= 1.93\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 8200 ==========\n",
      "train loss= 1.88\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 8300 ==========\n",
      "train loss= 1.86\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 8400 ==========\n",
      "train loss= 1.87\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG \n",
      "\n",
      "========== global step= 8500 ==========\n",
      "train loss= 1.87\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG \n",
      "\n",
      "========== global step= 8600 ==========\n",
      "train loss= 1.89\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG \n",
      "\n",
      "========== global step= 8700 ==========\n",
      "train loss= 1.89\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG \n",
      "\n",
      "========== global step= 8800 ==========\n",
      "train loss= 1.92\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG \n",
      "\n",
      "========== global step= 8900 ==========\n",
      "train loss= 1.89\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG \n",
      "\n",
      "========== global step= 9000 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9100 ==========\n",
      "train loss= 1.90\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9200 ==========\n",
      "train loss= 1.93\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9300 ==========\n",
      "train loss= 1.91\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9400 ==========\n",
      "train loss= 1.98\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9500 ==========\n",
      "train loss= 1.92\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9600 ==========\n",
      "train loss= 1.96\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9700 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9800 ==========\n",
      "train loss= 1.97\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 9900 ==========\n",
      "train loss= 1.93\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10000 ==========\n",
      "train loss= 1.96\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10100 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10200 ==========\n",
      "train loss= 2.00\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10300 ==========\n",
      "train loss= 1.95\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10400 ==========\n",
      "train loss= 1.97\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10500 ==========\n",
      "train loss= 1.96\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10600 ==========\n",
      "train loss= 1.96\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10700 ==========\n",
      "train loss= 1.97\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10800 ==========\n",
      "train loss= 1.95\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 10900 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11000 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11100 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11200 ==========\n",
      "train loss= 1.90\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11300 ==========\n",
      "train loss= 1.93\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11400 ==========\n",
      "train loss= 1.90\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11500 ==========\n",
      "train loss= 1.91\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11600 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11700 ==========\n",
      "train loss= 1.89\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11800 ==========\n",
      "train loss= 1.90\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 11900 ==========\n",
      "train loss= 1.90\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 12000 ==========\n",
      "train loss= 1.91\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 12100 ==========\n",
      "train loss= 1.91\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 12200 ==========\n",
      "train loss= 1.94\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S IH0 NG Z \n",
      "\n",
      "========== global step= 12300 ==========\n",
      "train loss= 1.95\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S AY2 NG Z \n",
      "\n",
      "========== global step= 12400 ==========\n",
      "train loss= 1.91\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 Z AY2 NG Z \n",
      "\n",
      "========== global step= 12500 ==========\n",
      "train loss= 1.91\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S AY2 NG Z \n",
      "\n",
      "========== global step= 12600 ==========\n",
      "train loss= 1.89\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH0 S AY2 NG Z \n",
      "\n",
      "========== global step= 12700 ==========\n",
      "train loss= 1.93\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH0 S AY2 NG Z \n",
      "\n",
      "========== global step= 12800 ==========\n",
      "train loss= 1.91\n",
      "input: tydings\n",
      "expected: T AY1 D IH0 NG Z\n",
      "got: T IH1 S AY2 NG Z \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-818dd9e0f98b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_gs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(train_init_op)\n",
    "    \n",
    "    sv = tf.train.Saver()\n",
    "    sv.saver.save(sess, hp.logdir + '/model_epoch_%02d_gs_%d' % (epoch, gs))\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # training\n",
    "            _, _gs = sess.run([train_op, global_step])\n",
    "            \n",
    "            \n",
    "            # evaluation\n",
    "            if _gs%params[\"eval_steps\"]==0:\n",
    "                _loss = sess.run(loss)\n",
    "                print(\"=\"*10, \"global step=\", _gs, \"=\"*10)\n",
    "                print(\"train loss= %.2f\" % _loss)\n",
    "                \n",
    "                sess.run(eval_init_op)\n",
    "                _words, _preds, _prons = sess.run([words, preds, prons])\n",
    "                \n",
    "                ## logging\n",
    "                _w = _words[0].decode('utf-8')\n",
    "                _gt = _prons[0].decode('utf-8')\n",
    "                _p = \" \".join(m.idx2p[each] for each in _preds[0]).split(\"<EOS>\")[0]\n",
    "                print(\"input:\", _w)\n",
    "                print(\"expected:\", _gt)\n",
    "                print(\"got:\", _p)\n",
    "                print()\n",
    "            \n",
    "        except tf.errors.OutOfRangeError: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "82t4Dmwp73--"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GJ3Wxjyj73_C"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lkepUO4B_Vug"
   },
   "outputs": [],
   "source": [
    "test_batches = input_fn(test_words, \"\", params[\"maxlen\"], params[\"batch_size\"], \\\n",
    "                                                          shuffle=False, num_repeat=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4qZBN8D273_H"
   },
   "outputs": [],
   "source": [
    "# create a iterator of the correct shape and type\n",
    "iter = tf.data.Iterator.from_structure(test_batches.output_types, test_batches.output_shapes)\n",
    "xs, ys = iter.get_next()\n",
    "\n",
    "# create the initialisation operations\n",
    "test_init_op = iter.make_initializer(test_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jUyYlI4S73_O",
    "outputId": "ae0592d3-14b0-4f3b-94f8-ebc293c48304"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'IteratorGetNext:0' shape=(?, ?) dtype=int32>,\n",
       " <tf.Tensor 'IteratorGetNext:1' shape=(?,) dtype=int32>,\n",
       " <tf.Tensor 'IteratorGetNext:2' shape=(?,) dtype=string>)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sJHOcfYO73_g",
    "outputId": "204cc139-5eaf-416c-beab-0c1e38c0a8ea",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable decode/rnn/gru_cell/gates/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-11-b0c029ca6eb3>\", line 44, in decode\n    outputs, _ = tf.nn.dynamic_rnn(cell, inputs, initial_state=h0, dtype=tf.float32)\n  File \"<ipython-input-15-12d5d59b25f7>\", line 6, in <module>\n    logits, preds, _, _ = m.decode(inputs, h0=last_hidden, mode=\"infer\")\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-12d5d59b25f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<BOS>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"maxlen\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlast_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<BOS>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m   \u001b[0;34m)\u001b[0m  \u001b[0;31m# shifted right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b0c029ca6eb3>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, ys, h0, mode)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGRUCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hidden_units\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3289\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3291\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3002\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3004\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3005\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2937\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   2938\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3258\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3259\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3260\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    838\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    839\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\n\u001b[0;32m--> 370\u001b[0;31m                                      *args, **kwargs)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m           \u001b[0;31m# the user has manually overwritten the build method do we need to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m           \u001b[0;31m# build it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m         \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;34m\"gates/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         initializer=self._kernel_initializer)\n\u001b[0m\u001b[1;32m    537\u001b[0m     self._gate_bias = self.add_variable(\n\u001b[1;32m    538\u001b[0m         \u001b[0;34m\"gates/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_BIAS_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;34m\"\"\"Alias for `add_weight`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_subclass_implementers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             getter=vs.get_variable)\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    610\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    637\u001b[0m     new_variable = getter(\n\u001b[1;32m    638\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1485\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1235\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    538\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    490\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    859\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 861\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    862\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable decode/rnn/gru_cell/gates/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-11-b0c029ca6eb3>\", line 44, in decode\n    outputs, _ = tf.nn.dynamic_rnn(cell, inputs, initial_state=h0, dtype=tf.float32)\n  File \"<ipython-input-15-12d5d59b25f7>\", line 6, in <module>\n    logits, preds, _, _ = m.decode(inputs, h0=last_hidden, mode=\"infer\")\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "m = Model(params)\n",
    "last_hidden, words = m.encode(xs)\n",
    "\n",
    "preds = tf.fill((tf.shape(last_hidden)[0], 1), m.p2idx[\"<BOS>\"])\n",
    "for t in range(params[\"maxlen\"]):\n",
    "    logits, _preds, _, _ = m.decode(preds, h0=last_hidden, mode=\"infer\")\n",
    "    preds = _preds\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dy-BWWIu73_n"
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(test_init_op)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            # training\n",
    "            _preds = sess.run([preds])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Seq2seq tutorial with g2p.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
